\newpage
\section{Barrier synchronisation}
\inlineScala

A \emph{barrier synchronisation} object is used to synchronise some number of threads.
These are typically used in shared memory programs which progress in rounds; the barrier synchronisation is used to synchronise the threads at the end of each round ensuring the thread-safety of the shared memory. Such programs which use \emph{global synchronisations} (synchronising all threads) typically operate by instantiating some barrier object and then having each thread call |sync| on the barrier once they have completed their current round. Each call to |sync| only returns after all threads have called |sync|, synchronising all the threads at that point in time and allowing the threads to proceed afterwards \cite{CP}.
%This allows for a program with threads working on some shared memory which all threads can update to use a number of rounds of synchronisation in order to ensure thread-safety. Programs which use \emph{global synchronisations} (synchronising all threads) typically operate by instantiating some barrier object and then having each thread call |sync| on the barrier once they have completed their current round. Each call to |sync| only returns after all threads have called |sync|, synchronising all the threads at that point in time and allowing the threads to proceed afterwards \cite{CP}.



Here we present a novel model and analysis of an |n|-thread barrier synchronisation object which internally uses a binary heap of |n| two-thread signalling objects. The Scala code for the barrier object can be found at \cite{LoweBarrier}.

\subsection{The signalling object}

We first consider the signalling object |Signal|. This is used to synchronise between a parent and child thread, providing three external operations:

\begin{itemize}
  \item |signalUpAndWait| is used by the child to signal to the parent that the child is ready to synchronise and waits until the parent signals back;
  \item |waitForSignalUp| is used by the parent to wait for the child to be ready;
  \item |signalDown| is used by the parent to indicate to the child that the synchronisation has completed.
\end{itemize}

The Scala code for the |Signal| object can be found in figure \ref{scala:Signal}. Internally, the |Signal| object makes use of a private Boolean variable |state| with |true| indicating that a child is waiting and |false| otherwise. The use of this variable is protected by a JVM monitor.
\newpage 
\begin{scala}[label=scala:Signal, caption={The {\scalastyle Signal} object from \cite{LoweBarrier}}]
private class Signal{
  /** The state of this object.  true represents that the child has signalled,
    * but not yet received a signal back. */
  private var state = false

  /** Signal to the parent, and wait for a signal back. */
  def signalUpAndWait = synchronized{
    require(!state, 
      "Illegal state of Barrier: this might mean that it is\n"+
      "being used by two threads with the same identity.");
    state = true; notify()
    while(state) wait()
  }

  /** Wait for a signal from the child. */
  def waitForSignalUp = synchronized{ while(!state) wait() }

  /** Signal to the child. */
  def signalDown = synchronized{ state = false; notify() }
}
\end{scala}

The |signalUpAndWait| function first asserts that there currently is no other child waiting for the parent to complete a |signalDown|; this ensures that only one child thread uses a |Signal| object. It then sets |state| to |true|, indicating that the child is now waiting and it notifies the parent, waking them if they are waiting. The child thread then waits until the parent sets |state| to |false| and notifies the child; the use of the |while| loop here is to guard against spurious wakeups.

|waitForSignalUp| is used by a parent to wait for the child node to perform a |signalUpAndWait| and notify the parent; the |while| loop again guards against spurious wakeups.

The |signalDown| function is used to signal to the child that the synchronisation has been completed and that the child can return from its |signalUpAndWait| call.

\subsubsection{Modelling the Signal objects}

We use our model for a JVM monitor from section \ref{section:JVMMonitor} in our modelling of the |Signal| object. We define the dataype |SignalID = S.{0..n-1}| where |n| is the number of threads and the |datatype MonitorID = SigM.SignalID|; these allow us to specify the |Signal| object we are using and that object's monitor respectively.

For each of the three operations, a thread will first communicates a |callX| before running the |syncX| process within a |Synchronized| block (as defined in section \ref{listing::JVMMonitorInterface}).%revisit: could remove if wanted.
%In each case the calling |Proc| will first run the procedure |Func| which communicates the function and the |SignalID| that has been called by a given |ThreadID|. 

%\framebox{From signal-scala.csp}
 \begin{cspm}[caption={The state variable(s) and the function call channels}]
Var(value, get, set) = 
  get?_!value -> Var(value, get, set)
[] set?_?value' -> Var(value', get, set)

channel getState, setState : SignalID . ThreadID . Bool
stateChannels(s) = {|getState.s, setState.s|}

State :: (SignalID) -> Proc
State(s) = Var(false, getState.s, setState.s)

channel callSignalUpAndWait, callWaitForSignalUp, callSignalDown : SignalID . ThreadID
signalChannels = {|callSignalUpAndWait, callWaitForSignalUp, callSignalDown|}
 \end{cspm}

We first initialise the |state| variable, with the |SignalID| parameter in the channels indicating the |Signal| object the variable belongs to. We also introduce the function call channels as indicated above.

\begin{cspm}[caption={The CSP model of the {\scalastyle signalUpAndWait} function of the {\scalastyle Signal} object}]
SignalUpAndWait :: (SignalID, ThreadID) -> Proc
SignalUpAndWait(s, t) = 
  callSignalUpAndWait.s.t -> Synchronized(SigM.s, t, syncSignalUpAndWait(s, t))
syncSignalUpAndWait(s, t) = 
  getState.s.t?val -> if val == true then DIV -- Required to be false
                      else setState.s.t.true -> 
                          Notify(SigM.s, t); SignalWaitingForFalse(s, t)


SignalWaitingForFalse :: (SignalID, ThreadID) -> Proc
SignalWaitingForFalse(s, t) = 
  getState.s.t?val -> if val == false then SKIP
                      else Wait(SigM.s, t); SignalWaitingForFalse(s, t)                            
\end{cspm}

The |SignalUpAndWait| process enters a JVM \inlineScala \CSPM{synchronized} block and checks that \CSPM{state} is not true, diverging if so. This divergence is used to model a failed assertion; the rest of the code is a more direct translation.

\begin{cspm}[caption={The CSP model of the {\scalastyle waitForSignalUp} function of the {\scalastyle Signal} object}]
WaitForSignalUp :: (SignalID, ThreadID) -> Proc  
WaitForSignalUp(s, t) = 
  callWaitForSignalUp.s.t -> Synchronized(SigM.s, t, syncWaitForSignalUp(s, t))        
syncWaitForSignalUp(s, t) = 
  getState.s.t?val -> if val == true then  SKIP 
                      else Wait(SigM.s, t); syncWaitForSignalUp(s, t)
\end{cspm}

This is a natural model of the Scala code presented earlier; thread |t| communicates that it has called |waitForSignalUp| on Signal |s|, enters a |synchronized| block and then simulates the \inlineScala|while| \inlineCSP loop used to guard against spurious wakeups.

\begin{cspm}[caption={The CSP model of the {\scalastyle signalDown} function of the {\scalastyle Signal} object}]
SignalDown :: (SignalID, ThreadID) -> Proc
SignalDown(s, t) = callSignalDown.s.t -> Synchronized(SigM.s, t, syncSignalDown(s, t))
syncSignalDown(s, t) = setState.s.t.false -> Notify(SigM.s, t); SKIP
\end{cspm}

|SignalDown| is the simplest function to model; it obtains the monitor's lock, sets the |state| variable to false and then notifies the child that the synchronisation has completed.

We now consider the initialisation of the |Signal| objects.

\begin{cspm}[caption={The initialisation of the {\scalastyle Signal} objects}]
InitialiseSignal(sig, threads) = 
  runWith(SigM.sig, threads [|stateChannels(sig)|] State(sig)) 
      \ union(stateChannels(sig), events) --Hides the variable channels and the monitor channels

allStateChannels(sigs) = {|getState.s, setState.s | s <- sigs|}
States(sigs) = ||| s <- sigs @ State(s)
monitors(sigs) = {SigM.s | s <- sigs}

InitialiseSignals(sigs, threads) = 
  runWithMultiple(monitors(sigs), threads [|allStateChannels(sigs)|] States(sigs))  
      \ union(allStateChannels(sigs), events)
\end{cspm}

We define processes |InitialiseSignal| and |InitialiseSignals| to initialise a single signal and multiple signals respectively. These synchronise the threads with the interleaving of the state variables and the monitors and then hide the internal behaviour of the |Signal| objects. |runWith| and |runWithMultiple| are used to initialise the monitor(s) for the initialised |Signal| object(s).

% The |Signal| process is simply the process representing the state variable, with channels |getState.s| and |setState.s|

\subsection{The Barrier object}
\inlineScala
When initialised, the |Barrier(n: Int)| object creates an array of |n| |Signal| objects, with these organised in the structure of a heap. As per the trait of a barrier synchronisation, |Barrier| only provides a single function |sync(me)| which takes the thread's identity as an input:

\begin{scala}[caption={The Scala definition of the {\scalastyle Barrier.sync} function from \cite{LoweBarrier}}]
/** Perform a barrier synchronisation.
  * @param me the unique identity of this thread. */
def sync(me: Int) = {
  require(0 <= me && me < n, 
    s"Illegal parameter $me for sync: should be in the range [0..$n).")
  val child1 = 2*me+1; val child2 = 2*me+2
  // Wait for children
  if(child1 < n) signals(child1).waitForSignalUp
  if(child2 < n) signals(child2).waitForSignalUp
  // Signal to parent and wait for signal back
  if(me != 0) signals(me).signalUpAndWait
  // Signal to children
  if(child1 < n) signals(child1).signalDown
  if(child2 < n) signals(child2).signalDown
}  
\end{scala}

This checks that the thread's identity is such that |signals(me)| does not cause an 
|ArrayIndexOutOfBoundsException|. It then waits for the thread's children (if they exist) to signal that they are ready to synchronise, before signalling to its parent that all of its children are ready to synchronise. Once the parent signals back that the synchronisation has occurred the thread notifies its children that the synchronisation has completed before returning. The exception to this is thread |0|, which has no parent to signal to. Line 11 of the |sync(0)| call can therefore be considered the linearization point of the barrier synchronisation.
%and all of its descendants are ready to synchronise, hence thread |0| reaching line 11 of its execution can be taken as the linearization point of when the barrier synchronisation occurs.

\subsubsection{Modelling the Barrier object}
\inlineCSP
\begin{cspm}[caption={The CSP model of a thread interacting with the {\scalastyle Barrier} object}]
Thread(T.me) = beginSync.T.me -> Sync(T.me) |~| end.T.me -> SKIP

Sync(T.me) = 
  let child1 = 2*me+1 
      child2 = 2*me+2
  within 
      (if (child1 < n) then WaitForSignalUp(S.(child1), T.me) else SKIP);
      (if (child2 < n) then WaitForSignalUp(S.(child2), T.me) else SKIP);
      (if (me != 0) then SignalUpAndWait(S.me, T.me) else SKIP);
      (if (child1 < n) then SignalDown(S.(child1), T.me) else SKIP);
      (if (child2 < n) then SignalDown(S.(child2), T.me) else SKIP);
      endSync.T.me -> Thread(T.me)

Threads = ||| t : ThreadID @ Thread(t)

BarrierSystem = InitialiseSignals(Threads) \ signalChannels
\end{cspm}

We recall from earlier that |datatype ThreadID = T.{0..n-1}| and |SignalID = S.{0..n-1}|. The process |Thread(T.me)| models the individual behaviour of a specific thread with identity |T.me :: ThreadID|. Each thread nondeterministically either communicate an |end.T.me| and terminates or starts a synchronisation. In the latter case |beginSync.T.me| is used to indicate the start of the synchronisation. The |Sync(T.me)| definition is very straightforward; the only change to the Scala definition is that |Sync(T.me)| communicates a |endSync.T.me| event just before it terminates.

The |Thread| processes are then interleaved together to yield |Threads|. We then initialise the |Signal| objects. We hide the channels of the |Signal| object, leaving \CSPM{\{|beginSync, endSync, spurious, end|\}} as the only visible channels of |BarrierSystem|.

\subsection{Correctness of the model}

We will show that the barrier synchronisation is correct; here correct requires that the synchronisation can be correctly linearized and if a synchronisation is possible then it will always occur. 

Correctly linearized in this context means that the barrier synchronisation can be considered to occur at some point between when all |n| threads have communicated |beginSync| and when the first thread communicates an |endSync| event. The requirement that a linearization must occur means that if all |n| threads communicate a |beginSync| then none of the threads can be blocked from communicating their respective |endSync|.

\begin{cspm}[caption={The linearizer specification for barrier synchronisations}]
Linearizer(t) = beginSync.t -> sync -> endSync.t -> Linearizer(t)
              |~| end.t -> STOP
Linearizers = || t <- ThreadID @ [{beginSync.t, sync, endSync.t, end.t}] Linearizer(t)
Spec = Linearizers \ {sync}
\end{cspm}

|Linearizer(t)| allows any thread to |beginSync.t| followed by an |endSync.t|, representing the call and return of |barrier.sync()|. The |sync| event can be considered to be the point at which the barrier synchronisation occurs since all threads must synchronise on this, fulfilling the requirement above. Additionally, each thread can terminate via |end.t|, indicating that it will perform no further synchronisations. This blocks all other threads from completing a barrier synchronisation, which is the intended behaviour.

We first note that |BarrierSystem| is divergence-free, but \CSPM{BarrierSystem \ \{|spurious|\}} is not. |BarrierSystem| being divergence-free with spurious wakeups visible is relevant as this means that we never breach the assertion in the |SignalUpAndWait| function and that no internal divergence can be caused by a finite number of spurious wakeups. This therefore means hiding the |spurious| events must be the cause of the divergences.
%\framebox{check that isn't an internal divergence caused by hiding spurious}. 
This is expected behaviour as one thread could spuriously wakeup, check the test condition and wait again before spuriously waking again indefinitely. This is still not a particular cause for concern; in practice spurious wakeups occur infrequently within the JVM.

We now consider the traces model, where we have that the following holds:
\begin{cspm}
assert Spec [T= BarrierSystem \ {|spurious|}
\end{cspm}
This means that |BarrierSystem| fulfils the linearization requirement of |Spec| i.e.~that it can be linearized and that the synchronisation between all |n| threads occurs correctly (if indeed it does occur).

Since |Spec| cannot diverge we will also consider refinement under the stable-failures model. This ensures that if a synchronisation can occur then it must occur and that all threads can then return.
%Using the stable failures model is valid as we only care about the behaviour of the |BarrierSpurSystem| in its stable states (i.e.~where the |Reg| process nondeterministically blocks |spurious| events); it could perform an indefinite number of successive |spurious| events, but this is an issue with the underlying JVM and not our barrier synchronisation object. 


% We note that using the stable failures model is normally inappropriate for a system that can diverge. However, this is valid here as for any state that could be unstable due to a hidden |spurious| there exists a corresponding stable state where the regulator process |Reg| blocks the spurious wakeup. 
Similarly to section \ref{section:SCLMonitor-Correctness} we will check refinement under the stable-failures model even though the model can diverge. This is valid as for every state that could be unstable due to a hidden |spurious| there exists a corresponding stable state where the regulator process |Reg| blocks the spurious wakeup.
FDR yields that the following assertion holds for systems of up to 6 threads; this can be verified in 1280 seconds.

\begin{cspm}
assert Spec [F= BarrierSystem \ {|spurious|}
\end{cspm}

As a result, we have that the |Barrier| object presented earlier is a correct implementation of barrier synchronisation for $n \leq 6$. This gives us significant confidence that the system is correct for larger $n$.

\subsection{Specification processes for the Signal objects}%revisit: name

Our current model of |Signal| models all the internal workings of the object, modelling the |synchronized| blocks and the internal |state| variable. This direct model is rather complex; we can only test for correctness on models with up to 6 threads in reasonable time.
%the number of states that FDR generate being exponential in the number of threads, resulting in us only being able to test refinement on a system of size 6 in reasonable time. 
We can instead construct a specification process which models the use of the |Signal| object. Though this still results in a model size exponential in the number of threads, the model will be of significantly smaller size. This will allow us to verify the |Barrier| object for larger numbers of threads.

By inspecting the usage of |Signal| we observe that there are two synchronisations between threads performed by each |Signal| object %\framebox{Diagram}
\inlineScala
\begin{itemize}
  \item |waitForSignalUp| and |signalUpAndWait| synchronise to indicate that that all threads using objects in this subtree are waiting to synchronise. This synchronisation has the parent waiting on the child to signal, with the child being allowed to signal and progress immediately
  \item |signalDown| and |signalUpAndWait| synchronise, with the parent signalling to the child that the barrier synchronisation has occurred and that |signalUpAndWait| can return. This synchronisation has the child thread waiting on the parent signalling down to it; the child thread is always waiting first as the child starts waiting on this synchronisation immediately after the previous synchronisation occurs.
\end{itemize}
\inlineCSP
We can model this simplified |Signal| object via the following CSP:

  \begin{cspm}[caption={The CSP model of the specification {\scalastyle Signal} object}]
channel endWaitForSignalUp, endSignalUpAndWait : SignalID . ThreadID
waitChannels = {|endWaitForSignalUp, endSignalUpAndWait|}

-- Simplified spec for a correctly used Signal object
SpecSig(s) = 
    callSignalUpAndWait.s?t -> callWaitForSignalUp.s?t2 -> SpecSig2(s, t, t2)
  [] callWaitForSignalUp.s?t2 -> callSignalUpAndWait.s?t -> SpecSig2(s, t, t2)
SpecSig2(s, t, t2) = 
  endWaitForSignalUp.s.t2 -> callSignalDown.s.t2 -> endSignalUpAndWait.s.t -> SpecSig(s)

-- The individual functions for the Signal object
SpecSignalUpAndWait(s, t) = callSignalUpAndWait.s.t -> endSignalUpAndWait.s.t -> SKIP
SpecWaitForSignalUp(s, t) = callWaitForSignalUp.s.t -> endWaitForSignalUp.s.t -> SKIP
SpecSignalDown(s, t) = callSignalDown.s.t -> SKIP

-- Construct the system for each of the SpecSig objects
SpecSignals = 
  || s <- SignalID @ [{|callSignalUpAndWait.s, callWaitForSignalUp.s, 
                        callSignalDown.s, endWaitForSignalUp.s, endSignalUpAndWait.s|}] 
                      SpecSig(s)

-- Method for barrier-sync to initialise the two objects
InitialiseSpecSignals(threads) = 
  (SpecSignals [|union(signalChannels, waitChannels)|] threads) \ waitChannels                     
  \end{cspm} 

We introduce channels |endWaitForSignalUp| and |endSignalUpAndWait| to represent the synchronisations between the child and parent, with each of the channels indicating that their respective functions are able to return. |SpecSig(s)| is used to dictate the order that communications are allowed to occur:

\begin{enumerate}
  \item Initially, it can either communicate a |callSignalUpAndWait| from the child thread or a |callWaitForSignalUp| from the parent. It then communicates the other event.
  \item It then communicates an |endWaitForSignalUp| to indicate to the parent that the first synchronisation has occurred.
  \item The parent then commmunicates a |callSignalDown| indicating that the barrier synchronisation has occured.
  \item Finally, an |endSignalUpAndWait| is communicated to indicate to the child that they can now terminate; |SpecSig(s)| then repeats.
\end{enumerate}

We also define the specification versions of the three external methods offered by a |Signal| object. |SpecSignalUpAndWait| and |SpecWaitForSignalUp| both initially communicate an event indicating that they have been `called' before communicating a |endSignalUpAndWait| or |endWaitForSignalUp| respectively before terminating. By contrast, |SpecSignalDown| immediately terminates after communicating that it has been `called' as it does not require a second synchronisation with another thread.

Finally for the |Signal| specifications, we let |SpecSignals| be the alphabetised parallel composition of each of the |SpecSig(s)| processes, with the parallel composition forcing each specification object to only synchronise on events with the matching |SignalID|. The individual threads and the overall system are defined similaly to the above, with the exception that all calls are to the specification processes and not the originals.

%revisit
%\framebox{Stuff about how the initial implementation of Signal fulfils this specification?}

\begin{cspm}[caption={The implementation of the {\scalastyle Barrier} based on }]
-- sThread is the same as Thread but uses the spec Signal
sThread(T.me) = beginSync.T.me -> sSync(T.me) |~| end.T.me -> SKIP
sSync(T.me) = 
  let child1 = 2*me+1 
      child2 = 2*me+2
  within (if (child1 < n) then SpecWaitForSignalUp(S.(child1), T.me) else SKIP);
        (if (child2 < n) then SpecWaitForSignalUp(S.(child2), T.me) else SKIP);
        (if me != 0 then SpecSignalUpAndWait(S.me, T.me) else SKIP);
        (if (child1 < n) then SpecSignalDown(S.(child1), T.me) else SKIP);
        (if (child2 < n) then SpecSignalDown(S.(child2), T.me)else SKIP);
        endSync.T.me -> sThread(T.me)

-- Initialise the spec system
sThreads = ||| t : ThreadID @ sThread(t)     
sBarrierSystem = InitialiseSpecSignals(sThreads)

assert Spec [FD= sBarrierSystem
\end{cspm}

Since the simplified |Signal| object does not use monitors we have that the system should be divergence-free. This is verified by FDR as the above refinement holds against our (divergence-free) linearization checker. We have that using the simpler specification |Signal|s result in model checking with 10 threads being possible in reasonable time. This is a significant increase over the natural model and significantly increases our confidence in the correctness of the |Barrier| object.


%\framebox{Proper performance comparison Simplified can run 10 threads in about the same time?}

%\framebox{the normal version can run 6}






